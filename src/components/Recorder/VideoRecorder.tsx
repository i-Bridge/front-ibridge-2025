'use client';

import { useRef, useState, useEffect } from 'react';
import { useParams } from 'next/navigation';
import { Fetcher } from '@/lib/fetcher';

export default function VideoRecorder({
  subjectId,
  onAIResponse,
}: {
  subjectId: number;
  onAIResponse: (message: string) => void;
}) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recognitionRef = useRef<any>(null);

  const [isRecording, setIsRecording] = useState(false);
  const [stream, setStream] = useState<MediaStream | null>(null);
  const [isThumbnailCaptured, setIsThumbnailCaptured] = useState(false);
  const [uploadedVideoUrl, setUploadedVideoUrl] = useState<string | null>(null);
  const [uploadedThumbnailUrl, setUploadedThumbnailUrl] = useState<
    string | null
  >(null);
  const [recognizedText, setRecognizedText] = useState('');
  const [answerId, setAnswerId] = useState<number | null>(null);

  const { childId } = useParams();

  const startRecording = async () => {
    if (mediaRecorderRef.current) return;

    try {
      console.log('ğŸ¬ ë…¹í™” ì‹œì‘ ìš”ì²­ë¨');
      const mediaStream = await navigator.mediaDevices.getUserMedia({
        video: true,
        audio: true,
      });
      setStream(mediaStream);
      setIsThumbnailCaptured(false);
      setUploadedVideoUrl(null);
      setUploadedThumbnailUrl(null);
      setRecognizedText('');
      setAnswerId(null);

      if (videoRef.current) {
        videoRef.current.srcObject = mediaStream;
        videoRef.current.play();
      }

      const chunks: BlobPart[] = [];
      const recorder = new MediaRecorder(mediaStream);

      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) chunks.push(event.data);
      };

      recorder.onstop = async () => {
        console.log('ğŸ›‘ ë…¹í™” ì¢…ë£Œë¨ â†’ ì˜ìƒ ì—…ë¡œë“œ ì‹œì‘');
        const blob = new Blob(chunks, { type: 'video/webm' });
        await uploadToS3(blob, 'video');
        mediaStream.getTracks().forEach((track) => track.stop());
        stopSTT();
      };

      mediaRecorderRef.current = recorder;
      recorder.start();
      setIsRecording(true);
      startSTT();

      setTimeout(() => {
        if (!isThumbnailCaptured) {
          console.log('ğŸ“¸ 3ì´ˆ ê²½ê³¼ â†’ ì¸ë„¤ì¼ ìº¡ì²˜ ì‹œë„');
          captureAndUploadThumbnail();
          setIsThumbnailCaptured(true);
        }
      }, 3000);
    } catch (err) {
      console.error('âŒ ë…¹í™” ì‹œì‘ ì‹¤íŒ¨:', err);
    }
  };

  const stopRecording = () => {
    console.log('ğŸ›‘ ë…¹í™” ì¤‘ì§€ ìš”ì²­ë¨');
    mediaRecorderRef.current?.stop();
    setIsRecording(false);
  };

  const startSTT = () => {
    console.log('ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘');
    const SpeechRecognition =
      (window as any).SpeechRecognition ||
      (window as any).webkitSpeechRecognition;
    if (!SpeechRecognition) {
      alert('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = 'ko-KR';
    recognition.interimResults = true;
    recognition.continuous = true;

    recognition.onresult = (event: any) => {
      let finalTranscript = '';
      for (let i = event.resultIndex; i < event.results.length; ++i) {
        finalTranscript += event.results[i][0].transcript;
      }
      console.log('ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:', finalTranscript);
      setRecognizedText(finalTranscript);
    };

    recognition.onerror = (e: any) => {
      console.error('ğŸ¤ ìŒì„± ì¸ì‹ ì˜¤ë¥˜:', e);
    };

    recognitionRef.current = recognition;
    recognition.start();
  };

  const stopSTT = () => {
    console.log('ğŸ›‘ ìŒì„± ì¸ì‹ ì¤‘ë‹¨');
    recognitionRef.current?.stop();
  };

  const captureAndUploadThumbnail = async () => {
    if (!videoRef.current || !canvasRef.current) return;

    console.log('ğŸ–¼ ì¸ë„¤ì¼ ìº¡ì²˜ ì¤‘...');
    const canvas = canvasRef.current;
    const video = videoRef.current;
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    const ctx = canvas.getContext('2d');
    ctx?.drawImage(video, 0, 0, video.videoWidth, video.videoHeight);

    canvas.toBlob(async (blob) => {
      if (!blob || !answerId) return;

      console.log('â˜ï¸ ì¸ë„¤ì¼ Presigned URL ìš”ì²­');
      const { data } = await Fetcher<{ url: string }>(
        `/child/${childId}/getURL`,
        {
          method: 'POST',
          data: { type: 'image', id: answerId },
          skipAuthHeader: true,
        },
      );

      if (!data?.url) {
        console.error('âŒ ì¸ë„¤ì¼ Presigned URL íšë“ ì‹¤íŒ¨');
        return;
      }

      const res = await fetch(data.url, { method: 'PUT', body: blob });
      if (res.ok) {
        const s3Url = data.url.split('?')[0];
        console.log('âœ… ì¸ë„¤ì¼ S3 ì—…ë¡œë“œ ì™„ë£Œ:', s3Url);
        setUploadedThumbnailUrl(s3Url);
      } else {
        console.error('âŒ ì¸ë„¤ì¼ S3 ì—…ë¡œë“œ ì‹¤íŒ¨');
      }
    }, 'image/jpeg');
  };

  const uploadToS3 = async (blob: Blob, type: 'video') => {
    if (!answerId) return;

    console.log('â˜ï¸ ì˜ìƒ Presigned URL ìš”ì²­');
    const { data } = await Fetcher<{ url: string }>(
      `/child/${childId}/getURL`,
      {
        method: 'POST',
        data: { type: 'video', id: answerId },
        skipAuthHeader: true,
      },
    );

    if (!data?.url) {
      console.error('âŒ ì˜ìƒ Presigned URL íšë“ ì‹¤íŒ¨');
      return;
    }

    const res = await fetch(data.url, { method: 'PUT', body: blob });
    if (res.ok) {
      const s3Url = data.url.split('?')[0];
      console.log('âœ… ì˜ìƒ S3 ì—…ë¡œë“œ ì™„ë£Œ:', s3Url);
      setUploadedVideoUrl(s3Url);
    } else {
      console.error('âŒ ì˜ìƒ S3 ì—…ë¡œë“œ ì‹¤íŒ¨');
    }
  };

  useEffect(() => {
    const sendToBackend = async () => {
      if (
        uploadedVideoUrl &&
        uploadedThumbnailUrl &&
        !isRecording &&
        recognizedText &&
        childId &&
        subjectId
      ) {
        console.log('ğŸ“¤ ë°±ì—”ë“œë¡œ ì „ì†¡ ì‹œì‘');
        console.log('ğŸ“ ì „ì†¡í•  í…ìŠ¤íŠ¸:', recognizedText);
        console.log('ğŸ¯ subjectId:', subjectId);

        const { data, isSuccess } = await Fetcher<{
          id: number;
          ai: string;
        }>(`/child/${childId}/answer`, {
          method: 'POST',
          data: { subjectId, text: recognizedText },
        });
        console.log('ğŸ“¥ /answer API ì‘ë‹µ:', { isSuccess, data });
        if (isSuccess && data) {
          console.log('âœ… í…ìŠ¤íŠ¸ ì‘ë‹µ ì €ì¥ ì™„ë£Œ. answerId:', data.id);
          setAnswerId(data.id);
          onAIResponse(data.ai);
          console.log('ğŸ“¤ S3 ì—…ë¡œë“œ ì™„ë£Œ ì•Œë¦¼ ì „ì†¡ ì‹œì‘');
          const uploadRes = await Fetcher(`/child/${childId}/uploaded`, {
            method: 'POST',
            data: {
              id: data.id,
              video: uploadedVideoUrl,
              image: uploadedThumbnailUrl,
            },
          });

          if (uploadRes.isSuccess) {
            console.log('âœ… ë°±ì—”ë“œì— ì—…ë¡œë“œ ì™„ë£Œ ì•Œë¦¼ ì „ì†¡ ì„±ê³µ');
          } else {
            console.warn('âš ï¸ ì—…ë¡œë“œ ì™„ë£Œ ì•Œë¦¼ ì‹¤íŒ¨');
          }
        }
      }
    };

    sendToBackend();
  }, [uploadedVideoUrl, uploadedThumbnailUrl, isRecording]);

  return (
    <div className="flex flex-col items-center gap-4">
      <video ref={videoRef} className="w-80 h-60 bg-black rounded" />
      <canvas ref={canvasRef} className="hidden" />
      <div className="text-gray-700 w-80 p-2 bg-white rounded shadow-sm text-sm">
        <strong>ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:</strong>{' '}
        {recognizedText || 'ë§ì„ í•´ë³´ì„¸ìš”...'}
      </div>
      {!isRecording ? (
        <button
          onClick={startRecording}
          className="px-6 py-3 bg-green-500 text-white rounded-lg"
          disabled={isRecording}
        >
          ë…¹í™” ì‹œì‘
        </button>
      ) : (
        <button
          onClick={stopRecording}
          className="px-6 py-3 bg-red-500 text-white rounded-lg"
        >
          ë…¹í™” ì¢…ë£Œ
        </button>
      )}
    </div>
  );
}
